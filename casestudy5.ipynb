{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWL9uA1vktSP"
      },
      "source": [
        "# Casestudy 5 - NLP Classifier\n",
        "\n",
        "### SPAM Dataset\n",
        "The dataset contains 5573 emails. They are labeled as spam and ham, where 4825 are ham (non spam) and 747 spam emails. We need to build a NLP classifier that specially uses word2vec from Google. Divide the dataset into 80 and 20 percent and build 3 types of models\n",
        "1. CBOW\n",
        "2. Skipgram\n",
        "3. Pretrained word2vec model from Google\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyyVrceuSP2n",
        "outputId": "84256a72-68c1-4c12-ae41-08790454755f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-09 04:17:07.984521: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.0/en_core_web_lg-3.4.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 587.7 MB 10 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (21.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (8.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.0.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKArt3YakOtT"
      },
      "outputs": [],
      "source": [
        "# Importing supporting directories\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pyplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFYK7F_pmC6L"
      },
      "outputs": [],
      "source": [
        "# Importing Word2Vec\n",
        "from gensim.models import Word2Vec as wtv\n",
        "# Importing Keyed Vectors\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugH-fjs4kjJf"
      },
      "outputs": [],
      "source": [
        "# Importing PCA\n",
        "from sklearn.decomposition import PCA\n",
        "# Import Label Encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Import Train Test Splitting \n",
        "from sklearn.model_selection import train_test_split\n",
        "# Build a text classification model using SVM\n",
        "from sklearn.svm import SVC\n",
        "# Check its accuracy\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "AaBsp00Z1qMY",
        "outputId": "0f679988-00fe-449d-f406-f63752002b9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dafa438b-1a42-41fa-a84e-bbf4e1d9ac1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dafa438b-1a42-41fa-a84e-bbf4e1d9ac1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dafa438b-1a42-41fa-a84e-bbf4e1d9ac1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dafa438b-1a42-41fa-a84e-bbf4e1d9ac1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     v1                                                 v2 Unnamed: 2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "\n",
              "  Unnamed: 3 Unnamed: 4  \n",
              "0        NaN        NaN  \n",
              "1        NaN        NaN  \n",
              "2        NaN        NaN  \n",
              "3        NaN        NaN  \n",
              "4        NaN        NaN  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading dataset\n",
        "df = pd.read_csv('/content/spam.csv', encoding='ISO-8859-1')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csfWNDvn126R",
        "outputId": "6f3a7337-04d6-4304-d366-e123b1fe0f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   v1          5572 non-null   object\n",
            " 1   v2          5572 non-null   object\n",
            " 2   Unnamed: 2  50 non-null     object\n",
            " 3   Unnamed: 3  12 non-null     object\n",
            " 4   Unnamed: 4  6 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 217.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byPPrdB1cZvY",
        "outputId": "c5b8e396-6d82-46c4-b42d-1c42cbe28cb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: v1, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['v1'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aegcogu3FGVO"
      },
      "source": [
        "## Initial Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWa2YOk8EyJO",
        "outputId": "deca2360-098e-4851-8a99-921db0355f00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "v1               0\n",
              "v2               0\n",
              "Unnamed: 2    5522\n",
              "Unnamed: 3    5560\n",
              "Unnamed: 4    5566\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking for missing values\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5LA-EVKogFf",
        "outputId": "631901b4-daf9-400e-8aba-f796ee5d7e72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " bt not his girlfrnd... G o o d n i g h t . . .@\"                                                                                                   3\n",
              " PO Box 5249                                                                                                                                        2\n",
              "this wont even start........ Datz confidence..\"                                                                                                     2\n",
              "GN                                                                                                                                                  2\n",
              " don't miss ur best life for anything... Gud nyt...\"                                                                                                2\n",
              " but dont try to prove it..\\\" .Gud noon....\"                                                                                                        2\n",
              " Gud night....\"                                                                                                                                     1\n",
              " like you are the KING\\\"...! OR \\\"Walk like you Dont care                                                                                           1\n",
              " HAD A COOL NYTHO                                                                                                                                   1\n",
              " PO Box 1146 MK45 2WT (2/3)\"                                                                                                                        1\n",
              " \\\"It is d wonderful fruit that a tree gives when it is being hurt by a stone.. Good night......\"                                                   1\n",
              " we made you hold all the weed\\\"\"                                                                                                                   1\n",
              " its a miracle to Love a person who can't Love anyone except U...\\\" Gud nyt...\"                                                                     1\n",
              " hopeSo hunny. i amnow feelin ill & ithink i may have tonsolitusaswell! damn iam layin in bedreal bored. lotsof luv me xxxx\\\"\"                      1\n",
              " that's the tiny street where the parking lot is\"                                                                                                   1\n",
              "PROBPOP IN & CU SATTHEN HUNNY 4BREKKIE! LOVE JEN XXX. PSXTRA LRG PORTIONS 4 ME PLEASE \\\"\"                                                           1\n",
              " SHE SHUDVETOLD U. DID URGRAN KNOW?NEWAY                                                                                                            1\n",
              " GOD said                                                                                                                                           1\n",
              " always give response 2 who cares 4 U\\\"... Gud night..swt dreams..take care\"                                                                        1\n",
              " HOPE UR OK... WILL GIVE U A BUZ WEDLUNCH. GO OUTSOMEWHERE 4 ADRINK IN TOWN..CUD GO 2WATERSHD 4 A BIT? PPL FROMWRK WILL BTHERE. LOVE PETEXXX.\\\"\"    1\n",
              " b'coz nobody will fight for u. Only u &amp; u have to fight for ur self &amp; win the battle. -VIVEKANAND- G 9t.. SD..\"                            1\n",
              "DEVIOUSBITCH.ANYWAY                                                                                                                                 1\n",
              " but watever u shared should be true\\\"....\"                                                                                                         1\n",
              " Dont Come Near My Body..!! Bcoz My Hands May Not Come 2 Wipe Ur Tears Off That Time..!Gud ni8\"                                                     1\n",
              " but dont try to prove\\\" ..... Gud mrng...\"                                                                                                         1\n",
              " the toughest is acting Happy with all unspoken pain inside..\\\"\"                                                                                    1\n",
              " HOWU DOIN? FOUNDURSELF A JOBYET SAUSAGE?LOVE JEN XXX\\\"\"                                                                                            1\n",
              " wanted to say hi. HI!!!\\\" Stop? Send STOP to 62468\"                                                                                                1\n",
              ".;-):-D\"                                                                                                                                            1\n",
              "just been in bedbut mite go 2 thepub l8tr if uwana mt up?loads a luv Jenxxx.\\\"\"                                                                     1\n",
              " I'll come up\"                                                                                                                                      1\n",
              " just as a shop has to give a guarantee on what they sell. B. G.\"                                                                                   1\n",
              " But at d end my love compromised me for everything:-(\\\".. Gud mornin:-)\"                                                                           1\n",
              " smoke hella weed\\\"\"                                                                                                                                1\n",
              "Well there's still a bit left if you guys want to tonight                                                                                           1\n",
              "\\\" not \\\"what i need to do.\\\"\"                                                                                                                      1\n",
              "JUST GOT PAYED2DAY & I HAVBEEN GIVEN Aå£50 PAY RISE 4MY WORK & HAVEBEEN MADE PRESCHOOLCO-ORDINATOR 2I AM FEELINGOOD LUV\\\"\"                          1\n",
              " justthought iåÕd sayhey! how u doin?nearly the endof me wk offdam nevamind!We will have 2Hook up sn if uwant m8? loveJen x.\\\"\"                     1\n",
              "JUST REALLYNEED 2DOCD.PLEASE DONTPLEASE DONTIGNORE MYCALLS                                                                                          1\n",
              "u hav2hear it!c u sn xxxx\\\"\"                                                                                                                        1\n",
              " I don't mind                                                                                                                                       1\n",
              " the person is definitely special for u..... But if the person is so special                                                                        1\n",
              " ENJOYIN INDIANS AT THE MO..yeP. SaLL gOoD HehE ;> hows bout u shexy? Pete Xx\\\"\"                                                                    1\n",
              "Name: Unnamed: 2, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Unnamed: 2'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWeUUrnxof4m",
        "outputId": "65f88a50-2400-4f6c-f086-9eb1f874230b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " MK17 92H. 450Ppw 16\"                         2\n",
              "GE                                            2\n",
              " why to miss them                             1\n",
              "U NO THECD ISV.IMPORTANT TOME 4 2MORO\\\"\"      1\n",
              "i wil tolerat.bcs ur my someone..... But      1\n",
              " ILLSPEAK 2 U2MORO WEN IM NOT ASLEEP...\\\"\"    1\n",
              "whoever is the KING\\\"!... Gud nyt\"            1\n",
              " TX 4 FONIN HON                               1\n",
              " \\\"OH No! COMPETITION\\\". Who knew             1\n",
              "IåÕL CALL U\\\"\"                                1\n",
              "Name: Unnamed: 3, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Unnamed: 3'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYEkJmm3nLmd",
        "outputId": "d3b22935-28aa-4ab0-e0ae-9b673eb44200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GNT:-)\"                                                     2\n",
              " just Keep-in-touch\\\" gdeve..\"                              1\n",
              " Never comfort me with a lie\\\" gud ni8 and sweet dreams\"    1\n",
              " CALL 2MWEN IM BK FRMCLOUD 9! J X\\\"\"                        1\n",
              " one day these two will become FREINDS FOREVER!\"            1\n",
              "Name: Unnamed: 4, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Unnamed: 4'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "L-G_aTtgFMaD",
        "outputId": "6766d611-7e3e-422b-be10-037255655b6a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a2835efd-5772-4bae-9e50-ad075b3089e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2835efd-5772-4bae-9e50-ad075b3089e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2835efd-5772-4bae-9e50-ad075b3089e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2835efd-5772-4bae-9e50-ad075b3089e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     v1                                                 v2\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Since the 3 Unnamed cols have together less than 1% of data we can drop them\n",
        "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yIXhiGvGmVP"
      },
      "outputs": [],
      "source": [
        "df.rename({'v1':'Category', 'v2':'Text'}, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk6V1GwdR2jL"
      },
      "source": [
        "## Preprocess Using Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHtxGWgVR8lD"
      },
      "outputs": [],
      "source": [
        "# Importing Spacy\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_lg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOddNFeQSiyM"
      },
      "outputs": [],
      "source": [
        "def spacy_process(text):\n",
        "    filtered = []\n",
        "    doc = nlp(text)\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct or token.is_space:\n",
        "            continue\n",
        "        if token.has_vector:\n",
        "            filtered.append(token.lemma_)\n",
        "    return \" \".join(filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDRtWMlQSx82"
      },
      "outputs": [],
      "source": [
        "df['spacytext'] = df['Text'].apply(spacy_process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zNgPBRIvTCYX",
        "outputId": "6145a78e-f44d-4bc8-8b3a-9ee0652cf17b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7aWMcgwTGiM",
        "outputId": "1871b57e-018c-4179-fece-7c4fc0880562"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       point crazy available n great world la e buffe...\n",
              "1                                   ok lar joke wif u oni\n",
              "2       free entry 2 comp win FA Cup final 21st 2005 t...\n",
              "3                                     U dun early hor u c\n",
              "4                                       nah think go live\n",
              "                              ...                        \n",
              "5567    2nd time try 2 contact u. U win Pound prize 2 ...\n",
              "5568                             Ì b go esplanade fr home\n",
              "5569                                 pity mood suggestion\n",
              "5570     guy bitch act like interested buy week give free\n",
              "5571                                                 true\n",
              "Name: spacytext, Length: 5572, dtype: object"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['spacytext']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJkSsPYnV2bU"
      },
      "outputs": [],
      "source": [
        "token_spacy = pd.Series(df['spacytext'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LleYP74F1N3O"
      },
      "source": [
        "## Preproccessing Using Simple Preprocess From Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On9JUN2n4WS5"
      },
      "outputs": [],
      "source": [
        "# Importing simple_preprocess\n",
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJpwyV3B3_dn"
      },
      "outputs": [],
      "source": [
        "# preprocess all the articles of the data set\n",
        "df['simpletext'] = df['Text'].apply(lambda x: simple_preprocess(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zoNi8P2Xc2cd",
        "outputId": "fda5c418-e254-4ef7-90fc-f5ab7ae51088"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRzIlL0d3_XZ",
        "outputId": "6432efae-da35-47cd-ed64-7e1bb4cac4a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['go',\n",
              " 'until',\n",
              " 'jurong',\n",
              " 'point',\n",
              " 'crazy',\n",
              " 'available',\n",
              " 'only',\n",
              " 'in',\n",
              " 'bugis',\n",
              " 'great',\n",
              " 'world',\n",
              " 'la',\n",
              " 'buffet',\n",
              " 'cine',\n",
              " 'there',\n",
              " 'got',\n",
              " 'amore',\n",
              " 'wat']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['simpletext'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83P5dUmfPhaG"
      },
      "outputs": [],
      "source": [
        "tokens_simple = pd.Series(df.simpletext.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33pRq1qrbm2s"
      },
      "source": [
        "## Preprocessing Using NLTK \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW21XF-ycbcj"
      },
      "outputs": [],
      "source": [
        "# Loading NLTK\n",
        "import nltk\n",
        "# Import regular expression\n",
        "import re\n",
        "# Import string\n",
        "import string\n",
        "# Import beautiful soup\n",
        "from bs4 import BeautifulSoup\n",
        "# Import Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "# Importing WordNetLemmatizer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUCJwME_b7hK",
        "outputId": "116940ae-e6ac-456a-e09d-51025c72eabc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# downloading punkt\n",
        "nltk.download('punkt')\n",
        "\n",
        "# downloading stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# downloading wordnet\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# downloading omw-1.4\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76nqGeySts5J"
      },
      "outputs": [],
      "source": [
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "# Converting to lower\n",
        "def to_lower(text):\n",
        "    return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GUc6zBjufZh"
      },
      "outputs": [],
      "source": [
        "#Define function for removing special characters (expansive)\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"I'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\^^\", \"\", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    return(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL0gh6KIhet_"
      },
      "outputs": [],
      "source": [
        "# Tokenizing Text\n",
        "def simple_tokenize(text):\n",
        "    return nltk.word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIKSMpREvcBb"
      },
      "outputs": [],
      "source": [
        "#Lemmatizing the text\n",
        "def simple_lemmatizer(token_list):\n",
        "    wlemma = WordNetLemmatizer()\n",
        "    return [wlemma.lemmatize(token) for token in token_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llHhG9sFjXxT"
      },
      "outputs": [],
      "source": [
        "# Removing Punctuation\n",
        "def remove_punct(token_list):\n",
        "    return [token for token in token_list if token not in string.punctuation]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUaWiQuCgXP7"
      },
      "outputs": [],
      "source": [
        "# Stopwords \n",
        "stop_words = stopwords.words('english')\n",
        "# Removing Stopwords\n",
        "def remove_stopwords(token_list):\n",
        "    return [token for token in token_list if token not in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3HQHiNFfTj2"
      },
      "outputs": [],
      "source": [
        "# NLTK Preprocessor\n",
        "def nltk_preprocess(text):\n",
        "    text = to_lower(text)\n",
        "    text = remove_special_characters(text)\n",
        "    text = simple_tokenize(text)\n",
        "    text = remove_punct(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = simple_lemmatizer(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2u0EbxEwNW_"
      },
      "outputs": [],
      "source": [
        "df['nltktext'] = df['Text'].apply(nltk_preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W3aenSRBkl8j",
        "outputId": "c2f1081e-4c03-43ff-8f0e-5d1f7bd40d55"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC-V9qKcksvA",
        "outputId": "f642248c-bf2e-4824-97d6-c78f347b0ad9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['go',\n",
              " 'jurong',\n",
              " 'point',\n",
              " 'crazy',\n",
              " 'available',\n",
              " 'bugis',\n",
              " 'n',\n",
              " 'great',\n",
              " 'world',\n",
              " 'la',\n",
              " 'e',\n",
              " 'buffet',\n",
              " 'cine',\n",
              " 'got',\n",
              " 'amore',\n",
              " 'wat']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['nltktext'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BiRYsqKllPP"
      },
      "outputs": [],
      "source": [
        "# Getting the values\n",
        "tokens = pd.Series(df.nltktext.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot1023xrc_Et"
      },
      "source": [
        "## 1. CBOW Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vfc9mlCy3_Mc"
      },
      "outputs": [],
      "source": [
        "# train a cbow model from the given data set\n",
        "cbow_model = wtv(tokens, size=300, window=9, min_count=2, sg=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWkHjokW3-vt"
      },
      "outputs": [],
      "source": [
        "# extract vectors from all words in doc\n",
        "def get_embedding_cbow(doc_tokens):\n",
        "    embeddings = []\n",
        "    model = cbow_model\n",
        "    # iterate over tokens to extract their vectors    \n",
        "    for tok in doc_tokens:\n",
        "        if tok in model.wv.vocab:\n",
        "            embeddings.append(model.wv.word_vec(tok))\n",
        "    # mean the vectors of individual words to get the vector of the statement\n",
        "    return np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuWz5y0-W9Cz",
        "outputId": "8ed94840-f9e2-49b9-c049-5de801854725"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "df['cbow_vectors'] = df['Text'].apply(lambda x: get_embedding_cbow(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9yF6H-5Ks8N",
        "outputId": "6def45f8-9d29-4468-f554-7d82d90f90eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Category         0\n",
              "Text             0\n",
              "spacytext        0\n",
              "simpletext       0\n",
              "nltktext         0\n",
              "cbow_vectors    54\n",
              "dtype: int64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cdxUypeKLRs6",
        "outputId": "003a3afa-de52-45ae-e054-1b4eefea5631"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-85ce5f8e-2498-4251-96ce-e1ce0c810e7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Text</th>\n",
              "      <th>spacytext</th>\n",
              "      <th>simpletext</th>\n",
              "      <th>nltktext</th>\n",
              "      <th>cbow_vectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>date SUNDAY</td>\n",
              "      <td>[have, date, on, sunday, with, will]</td>\n",
              "      <td>[date, sunday]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>ham</td>\n",
              "      <td>WHO ARE YOU SEEING?</td>\n",
              "      <td>see</td>\n",
              "      <td>[who, are, you, seeing]</td>\n",
              "      <td>[seeing]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>ham</td>\n",
              "      <td>HI BABE IM AT HOME NOW WANNA DO SOMETHING? XX</td>\n",
              "      <td>HI babe IM HOME WANNA xx</td>\n",
              "      <td>[hi, babe, im, at, home, now, wanna, do, somet...</td>\n",
              "      <td>[hi, babe, im, home, wan, na, something, xx]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444</th>\n",
              "      <td>ham</td>\n",
              "      <td>\\HEY HEY WERETHE MONKEESPEOPLE SAY WE MONKEYAR...</td>\n",
              "      <td>HEY HOWDY GORGEOUS</td>\n",
              "      <td>[hey, hey, werethe, monkeespeople, say, we, mo...</td>\n",
              "      <td>[hey, hey, werethe, monkeespeople, say, monkey...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>ham</td>\n",
              "      <td>LOOK AT AMY URE A BEAUTIFUL, INTELLIGENT WOMAN...</td>\n",
              "      <td>look AMY URE beautiful intelligent woman like ...</td>\n",
              "      <td>[look, at, amy, ure, beautiful, intelligent, w...</td>\n",
              "      <td>[look, amy, ure, beautiful, intelligent, woman...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>ham</td>\n",
              "      <td>WOT U WANNA DO THEN MISSY?</td>\n",
              "      <td>WOT U WANNA MISSY</td>\n",
              "      <td>[wot, wanna, do, then, missy]</td>\n",
              "      <td>[wot, u, wan, na, missy]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>ham</td>\n",
              "      <td>MAKE SURE ALEX KNOWS HIS BIRTHDAY IS OVER IN F...</td>\n",
              "      <td>SURE ALEX knows birthday minute FAR YOU'RE con...</td>\n",
              "      <td>[make, sure, alex, knows, his, birthday, is, o...</td>\n",
              "      <td>[make, sure, alex, know, birthday, fifteen, mi...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>ham</td>\n",
              "      <td>Y?WHERE U AT DOGBREATH? ITS JUST SOUNDING LIKE...</td>\n",
              "      <td>u sounding like JAN C AL</td>\n",
              "      <td>[where, at, dogbreath, its, just, sounding, li...</td>\n",
              "      <td>[ywhere, u, dogbreath, sounding, like, jan, c,...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908</th>\n",
              "      <td>ham</td>\n",
              "      <td>WHITE FUDGE OREOS ARE IN STORES</td>\n",
              "      <td>white FUDGE STORES</td>\n",
              "      <td>[white, fudge, oreos, are, in, stores]</td>\n",
              "      <td>[white, fudge, oreo, store]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>ham</td>\n",
              "      <td>LOOK AT THE FUCKIN TIME. WHAT THE FUCK YOU THI...</td>\n",
              "      <td>look fuckin TIME fuck think</td>\n",
              "      <td>[look, at, the, fuckin, time, what, the, fuck,...</td>\n",
              "      <td>[look, fuckin, time, fuck, think]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267</th>\n",
              "      <td>ham</td>\n",
              "      <td>SERIOUSLY. TELL HER THOSE EXACT WORDS RIGHT NOW.</td>\n",
              "      <td>seriously tell EXACT word right</td>\n",
              "      <td>[seriously, tell, her, those, exact, words, ri...</td>\n",
              "      <td>[seriously, tell, exact, word, right]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1295</th>\n",
              "      <td>ham</td>\n",
              "      <td>TELL HER I SAID EAT SHIT.</td>\n",
              "      <td>TELL say EAT shit</td>\n",
              "      <td>[tell, her, said, eat, shit]</td>\n",
              "      <td>[tell, said, eat, shit]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1643</th>\n",
              "      <td>ham</td>\n",
              "      <td>U WILL SWITCH YOUR FONE ON DAMMIT!!</td>\n",
              "      <td>u switch DAMMIT</td>\n",
              "      <td>[will, switch, your, fone, on, dammit]</td>\n",
              "      <td>[u, switch, fone, dammit]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1649</th>\n",
              "      <td>ham</td>\n",
              "      <td>ITS A LAPTOP TAKE IT WITH YOU.</td>\n",
              "      <td>LAPTOP</td>\n",
              "      <td>[its, laptop, take, it, with, you]</td>\n",
              "      <td>[laptop, take]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1749</th>\n",
              "      <td>ham</td>\n",
              "      <td>DO NOT B LATE LOVE MUM</td>\n",
              "      <td>b late LOVE MUM</td>\n",
              "      <td>[do, not, late, love, mum]</td>\n",
              "      <td>[b, late, love, mum]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1814</th>\n",
              "      <td>ham</td>\n",
              "      <td>HI ITS JESS I DONT KNOW IF YOU ARE AT WORK BUT...</td>\n",
              "      <td>hi jess dont know work U IM HOME EVE xxx</td>\n",
              "      <td>[hi, its, jess, dont, know, if, you, are, at, ...</td>\n",
              "      <td>[hi, jess, dont, know, work, call, u, im, home...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1878</th>\n",
              "      <td>ham</td>\n",
              "      <td>I AM AT A PARTY WITH ALEX NICHOLS</td>\n",
              "      <td>party ALEX nichols</td>\n",
              "      <td>[am, at, party, with, alex, nichols]</td>\n",
              "      <td>[party, alex, nichols]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1907</th>\n",
              "      <td>ham</td>\n",
              "      <td>ELLO BABE U OK?</td>\n",
              "      <td>BABE U ok</td>\n",
              "      <td>[ello, babe, ok]</td>\n",
              "      <td>[ello, babe, u, ok]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>ham</td>\n",
              "      <td>HI DARLIN IVE JUST GOT BACK AND I HAD A REALLY...</td>\n",
              "      <td>HI DARLIN IVE got nice night thank LIFT U tomo...</td>\n",
              "      <td>[hi, darlin, ive, just, got, back, and, had, r...</td>\n",
              "      <td>[hi, darlin, ive, got, back, really, nice, nig...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2033</th>\n",
              "      <td>ham</td>\n",
              "      <td>IM GONNA MISS U SO MUCH</td>\n",
              "      <td>IM GONNA MISS U</td>\n",
              "      <td>[im, gonna, miss, so, much]</td>\n",
              "      <td>[im, gon, na, miss, u, much]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2295</th>\n",
              "      <td>ham</td>\n",
              "      <td>HI DARLIN IM MISSIN U HOPE YOU ARE HAVING A GO...</td>\n",
              "      <td>HI DARLIN IM U HOPE have good TIME u TIME U ho...</td>\n",
              "      <td>[hi, darlin, im, missin, hope, you, are, havin...</td>\n",
              "      <td>[hi, darlin, im, missin, u, hope, good, time, ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2391</th>\n",
              "      <td>ham</td>\n",
              "      <td>PICK UR FONE UP NOW U DUMB?</td>\n",
              "      <td>PICK UR u dumb</td>\n",
              "      <td>[pick, ur, fone, up, now, dumb]</td>\n",
              "      <td>[pick, ur, fone, u, dumb]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2398</th>\n",
              "      <td>ham</td>\n",
              "      <td>YO YO YO BYATCH WHASSUP?</td>\n",
              "      <td>YO YO YO</td>\n",
              "      <td>[yo, yo, yo, byatch, whassup]</td>\n",
              "      <td>[yo, yo, yo, byatch, whassup]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2906</th>\n",
              "      <td>ham</td>\n",
              "      <td>ALRITE</td>\n",
              "      <td></td>\n",
              "      <td>[alrite]</td>\n",
              "      <td>[alrite]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2961</th>\n",
              "      <td>ham</td>\n",
              "      <td>\\NONE!NOWHERE IKNO DOESDISCOUNT!SHITINNIT\\\"\"</td>\n",
              "      <td></td>\n",
              "      <td>[none, nowhere, ikno, doesdiscount, shitinnit]</td>\n",
              "      <td>[nonenowhere, ikno, doesdiscountshitinnit]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3145</th>\n",
              "      <td>ham</td>\n",
              "      <td>\\SHIT BABE.. THASA BIT MESSED UP.YEH</td>\n",
              "      <td>BABE BIT MESSED</td>\n",
              "      <td>[shit, babe, thasa, bit, messed, up, yeh]</td>\n",
              "      <td>[shit, babe, thasa, bit, messed, upyeh]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3254</th>\n",
              "      <td>ham</td>\n",
              "      <td>HI ITS KATE CAN U GIVE ME A RING ASAP XXX</td>\n",
              "      <td>HI kate U ring asap XXX</td>\n",
              "      <td>[hi, its, kate, can, give, me, ring, asap, xxx]</td>\n",
              "      <td>[hi, kate, u, give, ring, asap, xxx]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3283</th>\n",
              "      <td>ham</td>\n",
              "      <td>ALRITE SAM ITS NIC JUST CHECKIN THAT THIS IS U...</td>\n",
              "      <td>sam NIC UR number</td>\n",
              "      <td>[alrite, sam, its, nic, just, checkin, that, t...</td>\n",
              "      <td>[alrite, sam, nic, checkin, ur, numberso, ittb]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3310</th>\n",
              "      <td>ham</td>\n",
              "      <td>HI DARLIN HOW WAS WORK DID U GET INTO TROUBLE?...</td>\n",
              "      <td>HI DARLIN work u trouble talked MUM MORNING go...</td>\n",
              "      <td>[hi, darlin, how, was, work, did, get, into, t...</td>\n",
              "      <td>[hi, darlin, work, u, get, trouble, ijust, tal...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3336</th>\n",
              "      <td>ham</td>\n",
              "      <td>I AM AT THE GAS STATION. GO THERE.</td>\n",
              "      <td>GAS station</td>\n",
              "      <td>[am, at, the, gas, station, go, there]</td>\n",
              "      <td>[gas, station, go]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3374</th>\n",
              "      <td>ham</td>\n",
              "      <td>:)</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3709</th>\n",
              "      <td>ham</td>\n",
              "      <td>ARE YOU IN TOWN? THIS IS V. IMPORTANT</td>\n",
              "      <td>TOWN V. important</td>\n",
              "      <td>[are, you, in, town, this, is, important]</td>\n",
              "      <td>[town, v, important]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3786</th>\n",
              "      <td>ham</td>\n",
              "      <td>WHORE YOU ARE UNBELIEVABLE.</td>\n",
              "      <td>WHORE UNBELIEVABLE</td>\n",
              "      <td>[whore, you, are, unbelievable]</td>\n",
              "      <td>[whore, unbelievable]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3937</th>\n",
              "      <td>ham</td>\n",
              "      <td>WHEN THE FIRST STRIKE IS A RED ONE. THE BIRD +...</td>\n",
              "      <td>strike red bird + begin BELIEVE + FLOWER</td>\n",
              "      <td>[when, the, first, strike, is, red, one, the, ...</td>\n",
              "      <td>[first, strike, red, one, bird, antelope, begi...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4017</th>\n",
              "      <td>ham</td>\n",
              "      <td>\\GRAN ONLYFOUND OUT AFEW DAYS AGO.CUSOON HONI\\\"\"</td>\n",
              "      <td>day</td>\n",
              "      <td>[gran, onlyfound, out, afew, days, ago, cusoon...</td>\n",
              "      <td>[gran, onlyfound, afew, day, agocusoon, honi]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4291</th>\n",
              "      <td>ham</td>\n",
              "      <td>G.W.R</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[gwr]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4331</th>\n",
              "      <td>ham</td>\n",
              "      <td>ALSO TELL HIM I SAID HAPPY BIRTHDAY</td>\n",
              "      <td>tell say happy birthday</td>\n",
              "      <td>[also, tell, him, said, happy, birthday]</td>\n",
              "      <td>[also, tell, said, happy, birthday]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4443</th>\n",
              "      <td>ham</td>\n",
              "      <td>COME BACK TO TAMPA FFFFUUUUUUU</td>\n",
              "      <td>come TAMPA</td>\n",
              "      <td>[come, back, to, tampa, ffffuuuuuuu]</td>\n",
              "      <td>[come, back, tampa, ffffuuuuuuu]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4464</th>\n",
              "      <td>ham</td>\n",
              "      <td>\\CHEERS FOR CALLIN BABE.SOZI CULDNT TALKBUT I ...</td>\n",
              "      <td>U DETAILS late CHAT properly</td>\n",
              "      <td>[cheers, for, callin, babe, sozi, culdnt, talk...</td>\n",
              "      <td>[cheer, callin, babesozi, culdnt, talkbut, wan...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4534</th>\n",
              "      <td>ham</td>\n",
              "      <td>IM LATE TELLMISS IM ON MY WAY</td>\n",
              "      <td>IM late IM way</td>\n",
              "      <td>[im, late, tellmiss, im, on, my, way]</td>\n",
              "      <td>[im, late, tellmiss, im, way]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4557</th>\n",
              "      <td>ham</td>\n",
              "      <td>PISS IS TALKING IS SOMEONE THAT REALISE U THAT...</td>\n",
              "      <td>piss talking u point read BACKWARDS</td>\n",
              "      <td>[piss, is, talking, is, someone, that, realise...</td>\n",
              "      <td>[piss, talking, someone, realise, u, point, it...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4570</th>\n",
              "      <td>ham</td>\n",
              "      <td>\\CHA QUITEAMUZING THATåÕSCOOL BABE</td>\n",
              "      <td>BABE</td>\n",
              "      <td>[cha, quiteamuzing, thatåõscool, babe]</td>\n",
              "      <td>[cha, quiteamuzing, thatscool, babe]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4619</th>\n",
              "      <td>ham</td>\n",
              "      <td>THIS IS A LONG FUCKIN SHOWR</td>\n",
              "      <td>long fuckin</td>\n",
              "      <td>[this, is, long, fuckin, showr]</td>\n",
              "      <td>[long, fuckin, showr]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4722</th>\n",
              "      <td>ham</td>\n",
              "      <td>HELLO PEACH! MY CAKE TASTS LUSH!</td>\n",
              "      <td>HELLO PEACH cake LUSH</td>\n",
              "      <td>[hello, peach, my, cake, tasts, lush]</td>\n",
              "      <td>[hello, peach, cake, tasts, lush]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4777</th>\n",
              "      <td>ham</td>\n",
              "      <td>U R THE MOST BEAUTIFUL GIRL IVE EVER SEEN. U R...</td>\n",
              "      <td>u R beautiful GIRL IVE see u r baby come C COM...</td>\n",
              "      <td>[the, most, beautiful, girl, ive, ever, seen, ...</td>\n",
              "      <td>[u, r, beautiful, girl, ive, ever, seen, u, r,...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4822</th>\n",
              "      <td>ham</td>\n",
              "      <td>:-) :-)</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>ham</td>\n",
              "      <td>\\HEY KATE</td>\n",
              "      <td>kate</td>\n",
              "      <td>[hey, kate]</td>\n",
              "      <td>[hey, kate]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5005</th>\n",
              "      <td>ham</td>\n",
              "      <td>ILL B DOWN SOON</td>\n",
              "      <td>ILL B soon</td>\n",
              "      <td>[ill, down, soon]</td>\n",
              "      <td>[ill, b, soon]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5155</th>\n",
              "      <td>ham</td>\n",
              "      <td>MY NEW YEARS EVE WAS OK. I WENT TO A PARTY WIT...</td>\n",
              "      <td>new YEARS EVE ok go party BOYFRIEND si HEY</td>\n",
              "      <td>[my, new, years, eve, was, ok, went, to, party...</td>\n",
              "      <td>[new, year, eve, ok, went, party, boyfriend, s...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5187</th>\n",
              "      <td>ham</td>\n",
              "      <td>WHAT TIME U WRKIN?</td>\n",
              "      <td>TIME U</td>\n",
              "      <td>[what, time, wrkin]</td>\n",
              "      <td>[time, u, wrkin]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>ham</td>\n",
              "      <td>WOT STUDENT DISCOUNT CAN U GET ON BOOKS?</td>\n",
              "      <td>WOT student discount U book</td>\n",
              "      <td>[wot, student, discount, can, get, on, books]</td>\n",
              "      <td>[wot, student, discount, u, get, book]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>ham</td>\n",
              "      <td>HI DARLIN ITS KATE ARE U UP FOR DOIN SOMETHIN ...</td>\n",
              "      <td>HI DARLIN kate u DOIN SOMETHIN tonight IM go p...</td>\n",
              "      <td>[hi, darlin, its, kate, are, up, for, doin, so...</td>\n",
              "      <td>[hi, darlin, kate, u, doin, somethin, tonight,...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>ham</td>\n",
              "      <td>\\ER</td>\n",
              "      <td></td>\n",
              "      <td>[er]</td>\n",
              "      <td>[er]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5388</th>\n",
              "      <td>ham</td>\n",
              "      <td>NOT MUCH NO FIGHTS. IT WAS A GOOD NITE!!</td>\n",
              "      <td>fights good nite</td>\n",
              "      <td>[not, much, no, fights, it, was, good, nite]</td>\n",
              "      <td>[much, fight, good, nite]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85ce5f8e-2498-4251-96ce-e1ce0c810e7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85ce5f8e-2498-4251-96ce-e1ce0c810e7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85ce5f8e-2498-4251-96ce-e1ce0c810e7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Category                                               Text  \\\n",
              "14        ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "43        ham                                WHO ARE YOU SEEING?   \n",
              "72        ham      HI BABE IM AT HOME NOW WANNA DO SOMETHING? XX   \n",
              "444       ham  \\HEY HEY WERETHE MONKEESPEOPLE SAY WE MONKEYAR...   \n",
              "456       ham  LOOK AT AMY URE A BEAUTIFUL, INTELLIGENT WOMAN...   \n",
              "569       ham                         WOT U WANNA DO THEN MISSY?   \n",
              "622       ham  MAKE SURE ALEX KNOWS HIS BIRTHDAY IS OVER IN F...   \n",
              "792       ham  Y?WHERE U AT DOGBREATH? ITS JUST SOUNDING LIKE...   \n",
              "908       ham                    WHITE FUDGE OREOS ARE IN STORES   \n",
              "983       ham  LOOK AT THE FUCKIN TIME. WHAT THE FUCK YOU THI...   \n",
              "1267      ham   SERIOUSLY. TELL HER THOSE EXACT WORDS RIGHT NOW.   \n",
              "1295      ham                          TELL HER I SAID EAT SHIT.   \n",
              "1643      ham                U WILL SWITCH YOUR FONE ON DAMMIT!!   \n",
              "1649      ham                     ITS A LAPTOP TAKE IT WITH YOU.   \n",
              "1749      ham                             DO NOT B LATE LOVE MUM   \n",
              "1814      ham  HI ITS JESS I DONT KNOW IF YOU ARE AT WORK BUT...   \n",
              "1878      ham                  I AM AT A PARTY WITH ALEX NICHOLS   \n",
              "1907      ham                                    ELLO BABE U OK?   \n",
              "1990      ham  HI DARLIN IVE JUST GOT BACK AND I HAD A REALLY...   \n",
              "2033      ham                            IM GONNA MISS U SO MUCH   \n",
              "2295      ham  HI DARLIN IM MISSIN U HOPE YOU ARE HAVING A GO...   \n",
              "2391      ham                        PICK UR FONE UP NOW U DUMB?   \n",
              "2398      ham                           YO YO YO BYATCH WHASSUP?   \n",
              "2906      ham                                             ALRITE   \n",
              "2961      ham       \\NONE!NOWHERE IKNO DOESDISCOUNT!SHITINNIT\\\"\"   \n",
              "3145      ham               \\SHIT BABE.. THASA BIT MESSED UP.YEH   \n",
              "3254      ham          HI ITS KATE CAN U GIVE ME A RING ASAP XXX   \n",
              "3283      ham  ALRITE SAM ITS NIC JUST CHECKIN THAT THIS IS U...   \n",
              "3310      ham  HI DARLIN HOW WAS WORK DID U GET INTO TROUBLE?...   \n",
              "3336      ham                 I AM AT THE GAS STATION. GO THERE.   \n",
              "3374      ham                                                :)    \n",
              "3709      ham              ARE YOU IN TOWN? THIS IS V. IMPORTANT   \n",
              "3786      ham                        WHORE YOU ARE UNBELIEVABLE.   \n",
              "3937      ham  WHEN THE FIRST STRIKE IS A RED ONE. THE BIRD +...   \n",
              "4017      ham   \\GRAN ONLYFOUND OUT AFEW DAYS AGO.CUSOON HONI\\\"\"   \n",
              "4291      ham                                              G.W.R   \n",
              "4331      ham                ALSO TELL HIM I SAID HAPPY BIRTHDAY   \n",
              "4443      ham                     COME BACK TO TAMPA FFFFUUUUUUU   \n",
              "4464      ham  \\CHEERS FOR CALLIN BABE.SOZI CULDNT TALKBUT I ...   \n",
              "4534      ham                      IM LATE TELLMISS IM ON MY WAY   \n",
              "4557      ham  PISS IS TALKING IS SOMEONE THAT REALISE U THAT...   \n",
              "4570      ham                 \\CHA QUITEAMUZING THATåÕSCOOL BABE   \n",
              "4619      ham                        THIS IS A LONG FUCKIN SHOWR   \n",
              "4722      ham                   HELLO PEACH! MY CAKE TASTS LUSH!   \n",
              "4777      ham  U R THE MOST BEAUTIFUL GIRL IVE EVER SEEN. U R...   \n",
              "4822      ham                                            :-) :-)   \n",
              "4992      ham                                          \\HEY KATE   \n",
              "5005      ham                                    ILL B DOWN SOON   \n",
              "5155      ham  MY NEW YEARS EVE WAS OK. I WENT TO A PARTY WIT...   \n",
              "5187      ham                                 WHAT TIME U WRKIN?   \n",
              "5202      ham           WOT STUDENT DISCOUNT CAN U GET ON BOOKS?   \n",
              "5266      ham  HI DARLIN ITS KATE ARE U UP FOR DOIN SOMETHIN ...   \n",
              "5268      ham                                                \\ER   \n",
              "5388      ham           NOT MUCH NO FIGHTS. IT WAS A GOOD NITE!!   \n",
              "\n",
              "                                              spacytext  \\\n",
              "14                                          date SUNDAY   \n",
              "43                                                  see   \n",
              "72                             HI babe IM HOME WANNA xx   \n",
              "444                                  HEY HOWDY GORGEOUS   \n",
              "456   look AMY URE beautiful intelligent woman like ...   \n",
              "569                                   WOT U WANNA MISSY   \n",
              "622   SURE ALEX knows birthday minute FAR YOU'RE con...   \n",
              "792                            u sounding like JAN C AL   \n",
              "908                                  white FUDGE STORES   \n",
              "983                         look fuckin TIME fuck think   \n",
              "1267                    seriously tell EXACT word right   \n",
              "1295                                  TELL say EAT shit   \n",
              "1643                                    u switch DAMMIT   \n",
              "1649                                             LAPTOP   \n",
              "1749                                    b late LOVE MUM   \n",
              "1814           hi jess dont know work U IM HOME EVE xxx   \n",
              "1878                                 party ALEX nichols   \n",
              "1907                                          BABE U ok   \n",
              "1990  HI DARLIN IVE got nice night thank LIFT U tomo...   \n",
              "2033                                    IM GONNA MISS U   \n",
              "2295  HI DARLIN IM U HOPE have good TIME u TIME U ho...   \n",
              "2391                                     PICK UR u dumb   \n",
              "2398                                           YO YO YO   \n",
              "2906                                                      \n",
              "2961                                                      \n",
              "3145                                    BABE BIT MESSED   \n",
              "3254                            HI kate U ring asap XXX   \n",
              "3283                                  sam NIC UR number   \n",
              "3310  HI DARLIN work u trouble talked MUM MORNING go...   \n",
              "3336                                        GAS station   \n",
              "3374                                                      \n",
              "3709                                  TOWN V. important   \n",
              "3786                                 WHORE UNBELIEVABLE   \n",
              "3937           strike red bird + begin BELIEVE + FLOWER   \n",
              "4017                                                day   \n",
              "4291                                                      \n",
              "4331                            tell say happy birthday   \n",
              "4443                                         come TAMPA   \n",
              "4464                       U DETAILS late CHAT properly   \n",
              "4534                                     IM late IM way   \n",
              "4557                piss talking u point read BACKWARDS   \n",
              "4570                                               BABE   \n",
              "4619                                        long fuckin   \n",
              "4722                              HELLO PEACH cake LUSH   \n",
              "4777  u R beautiful GIRL IVE see u r baby come C COM...   \n",
              "4822                                                      \n",
              "4992                                               kate   \n",
              "5005                                         ILL B soon   \n",
              "5155         new YEARS EVE ok go party BOYFRIEND si HEY   \n",
              "5187                                             TIME U   \n",
              "5202                        WOT student discount U book   \n",
              "5266  HI DARLIN kate u DOIN SOMETHIN tonight IM go p...   \n",
              "5268                                                      \n",
              "5388                                   fights good nite   \n",
              "\n",
              "                                             simpletext  \\\n",
              "14                 [have, date, on, sunday, with, will]   \n",
              "43                              [who, are, you, seeing]   \n",
              "72    [hi, babe, im, at, home, now, wanna, do, somet...   \n",
              "444   [hey, hey, werethe, monkeespeople, say, we, mo...   \n",
              "456   [look, at, amy, ure, beautiful, intelligent, w...   \n",
              "569                       [wot, wanna, do, then, missy]   \n",
              "622   [make, sure, alex, knows, his, birthday, is, o...   \n",
              "792   [where, at, dogbreath, its, just, sounding, li...   \n",
              "908              [white, fudge, oreos, are, in, stores]   \n",
              "983   [look, at, the, fuckin, time, what, the, fuck,...   \n",
              "1267  [seriously, tell, her, those, exact, words, ri...   \n",
              "1295                       [tell, her, said, eat, shit]   \n",
              "1643             [will, switch, your, fone, on, dammit]   \n",
              "1649                 [its, laptop, take, it, with, you]   \n",
              "1749                         [do, not, late, love, mum]   \n",
              "1814  [hi, its, jess, dont, know, if, you, are, at, ...   \n",
              "1878               [am, at, party, with, alex, nichols]   \n",
              "1907                                   [ello, babe, ok]   \n",
              "1990  [hi, darlin, ive, just, got, back, and, had, r...   \n",
              "2033                        [im, gonna, miss, so, much]   \n",
              "2295  [hi, darlin, im, missin, hope, you, are, havin...   \n",
              "2391                    [pick, ur, fone, up, now, dumb]   \n",
              "2398                      [yo, yo, yo, byatch, whassup]   \n",
              "2906                                           [alrite]   \n",
              "2961     [none, nowhere, ikno, doesdiscount, shitinnit]   \n",
              "3145          [shit, babe, thasa, bit, messed, up, yeh]   \n",
              "3254    [hi, its, kate, can, give, me, ring, asap, xxx]   \n",
              "3283  [alrite, sam, its, nic, just, checkin, that, t...   \n",
              "3310  [hi, darlin, how, was, work, did, get, into, t...   \n",
              "3336             [am, at, the, gas, station, go, there]   \n",
              "3374                                                 []   \n",
              "3709          [are, you, in, town, this, is, important]   \n",
              "3786                    [whore, you, are, unbelievable]   \n",
              "3937  [when, the, first, strike, is, red, one, the, ...   \n",
              "4017  [gran, onlyfound, out, afew, days, ago, cusoon...   \n",
              "4291                                                 []   \n",
              "4331           [also, tell, him, said, happy, birthday]   \n",
              "4443               [come, back, to, tampa, ffffuuuuuuu]   \n",
              "4464  [cheers, for, callin, babe, sozi, culdnt, talk...   \n",
              "4534              [im, late, tellmiss, im, on, my, way]   \n",
              "4557  [piss, is, talking, is, someone, that, realise...   \n",
              "4570             [cha, quiteamuzing, thatåõscool, babe]   \n",
              "4619                    [this, is, long, fuckin, showr]   \n",
              "4722              [hello, peach, my, cake, tasts, lush]   \n",
              "4777  [the, most, beautiful, girl, ive, ever, seen, ...   \n",
              "4822                                                 []   \n",
              "4992                                        [hey, kate]   \n",
              "5005                                  [ill, down, soon]   \n",
              "5155  [my, new, years, eve, was, ok, went, to, party...   \n",
              "5187                                [what, time, wrkin]   \n",
              "5202      [wot, student, discount, can, get, on, books]   \n",
              "5266  [hi, darlin, its, kate, are, up, for, doin, so...   \n",
              "5268                                               [er]   \n",
              "5388       [not, much, no, fights, it, was, good, nite]   \n",
              "\n",
              "                                               nltktext cbow_vectors  \n",
              "14                                       [date, sunday]          NaN  \n",
              "43                                             [seeing]          NaN  \n",
              "72         [hi, babe, im, home, wan, na, something, xx]          NaN  \n",
              "444   [hey, hey, werethe, monkeespeople, say, monkey...          NaN  \n",
              "456   [look, amy, ure, beautiful, intelligent, woman...          NaN  \n",
              "569                            [wot, u, wan, na, missy]          NaN  \n",
              "622   [make, sure, alex, know, birthday, fifteen, mi...          NaN  \n",
              "792   [ywhere, u, dogbreath, sounding, like, jan, c,...          NaN  \n",
              "908                         [white, fudge, oreo, store]          NaN  \n",
              "983                   [look, fuckin, time, fuck, think]          NaN  \n",
              "1267              [seriously, tell, exact, word, right]          NaN  \n",
              "1295                            [tell, said, eat, shit]          NaN  \n",
              "1643                          [u, switch, fone, dammit]          NaN  \n",
              "1649                                     [laptop, take]          NaN  \n",
              "1749                               [b, late, love, mum]          NaN  \n",
              "1814  [hi, jess, dont, know, work, call, u, im, home...          NaN  \n",
              "1878                             [party, alex, nichols]          NaN  \n",
              "1907                                [ello, babe, u, ok]          NaN  \n",
              "1990  [hi, darlin, ive, got, back, really, nice, nig...          NaN  \n",
              "2033                       [im, gon, na, miss, u, much]          NaN  \n",
              "2295  [hi, darlin, im, missin, u, hope, good, time, ...          NaN  \n",
              "2391                          [pick, ur, fone, u, dumb]          NaN  \n",
              "2398                      [yo, yo, yo, byatch, whassup]          NaN  \n",
              "2906                                           [alrite]          NaN  \n",
              "2961         [nonenowhere, ikno, doesdiscountshitinnit]          NaN  \n",
              "3145            [shit, babe, thasa, bit, messed, upyeh]          NaN  \n",
              "3254               [hi, kate, u, give, ring, asap, xxx]          NaN  \n",
              "3283    [alrite, sam, nic, checkin, ur, numberso, ittb]          NaN  \n",
              "3310  [hi, darlin, work, u, get, trouble, ijust, tal...          NaN  \n",
              "3336                                 [gas, station, go]          NaN  \n",
              "3374                                                 []          NaN  \n",
              "3709                               [town, v, important]          NaN  \n",
              "3786                              [whore, unbelievable]          NaN  \n",
              "3937  [first, strike, red, one, bird, antelope, begi...          NaN  \n",
              "4017      [gran, onlyfound, afew, day, agocusoon, honi]          NaN  \n",
              "4291                                              [gwr]          NaN  \n",
              "4331                [also, tell, said, happy, birthday]          NaN  \n",
              "4443                   [come, back, tampa, ffffuuuuuuu]          NaN  \n",
              "4464  [cheer, callin, babesozi, culdnt, talkbut, wan...          NaN  \n",
              "4534                      [im, late, tellmiss, im, way]          NaN  \n",
              "4557  [piss, talking, someone, realise, u, point, it...          NaN  \n",
              "4570               [cha, quiteamuzing, thatscool, babe]          NaN  \n",
              "4619                              [long, fuckin, showr]          NaN  \n",
              "4722                  [hello, peach, cake, tasts, lush]          NaN  \n",
              "4777  [u, r, beautiful, girl, ive, ever, seen, u, r,...          NaN  \n",
              "4822                                                 []          NaN  \n",
              "4992                                        [hey, kate]          NaN  \n",
              "5005                                     [ill, b, soon]          NaN  \n",
              "5155  [new, year, eve, ok, went, party, boyfriend, s...          NaN  \n",
              "5187                                   [time, u, wrkin]          NaN  \n",
              "5202             [wot, student, discount, u, get, book]          NaN  \n",
              "5266  [hi, darlin, kate, u, doin, somethin, tonight,...          NaN  \n",
              "5268                                               [er]          NaN  \n",
              "5388                          [much, fight, good, nite]          NaN  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['cbow_vectors'].isnull() == True]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk-0gCU-LRPY"
      },
      "source": [
        "The presence of these NaN values indicate that regardless of which preprocess we apply, these words/empty spaces result in empty vectors which means error in further process. So we can drop these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "gp1rq74UacHm",
        "outputId": "de0f3e2e-35a0-4b05-cd95-9327849a5af4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-12508af3-94d4-4b13-b932-94c109d17b7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Text</th>\n",
              "      <th>spacytext</th>\n",
              "      <th>simpletext</th>\n",
              "      <th>nltktext</th>\n",
              "      <th>cbow_vectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>point crazy available n great world la e buffe...</td>\n",
              "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "      <td>[-0.106335275, -0.06327503, 0.048476845, -0.19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joke wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, oni]</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>[-0.102702685, -0.061022747, 0.047203705, -0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry 2 comp win FA Cup final 21st 2005 t...</td>\n",
              "      <td>[free, entry, in, wkly, comp, to, win, fa, cup...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>[-0.09802247, -0.05802328, 0.044908598, -0.182...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>U dun early hor u c</td>\n",
              "      <td>[dun, say, so, early, hor, already, then, say]</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "      <td>[-0.13842326, -0.08239722, 0.062801085, -0.258...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah think go live</td>\n",
              "      <td>[nah, don, think, he, goes, to, usf, he, lives...</td>\n",
              "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
              "      <td>[-0.10480784, -0.062163178, 0.047725685, -0.19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>hey darle 3 week word like fun Tb ok std send</td>\n",
              "      <td>[freemsg, hey, there, darling, it, been, week,...</td>\n",
              "      <td>[freemsg, hey, darling, 3, week, word, back, i...</td>\n",
              "      <td>[-0.10340355, -0.06136291, 0.047242425, -0.192...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>brother like speak treat like aids patent</td>\n",
              "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
              "      <td>[-0.09139911, -0.053884435, 0.041671406, -0.17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "      <td>request Melle Melle Oru set Callers press 9 co...</td>\n",
              "      <td>[as, per, your, request, melle, melle, oru, mi...</td>\n",
              "      <td>[per, request, melle, melle, oru, minnaminungi...</td>\n",
              "      <td>[-0.13480254, -0.0804047, 0.061284255, -0.2514...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>WINNER value network customer select prize rew...</td>\n",
              "      <td>[winner, as, valued, network, customer, you, h...</td>\n",
              "      <td>[winner, valued, network, customer, selected, ...</td>\n",
              "      <td>[-0.11448016, -0.06814899, 0.052251305, -0.212...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>mobile 11 month u r entitle update late colour...</td>\n",
              "      <td>[had, your, mobile, months, or, more, entitled...</td>\n",
              "      <td>[mobile, 11, month, u, r, entitled, update, la...</td>\n",
              "      <td>[-0.08530863, -0.05060905, 0.03882869, -0.1585...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ham</td>\n",
              "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
              "      <td>go to home soon want talk stuff anymore tonigh...</td>\n",
              "      <td>[gonna, be, home, soon, and, don, want, to, ta...</td>\n",
              "      <td>[im, gon, na, home, soon, dont, want, talk, st...</td>\n",
              "      <td>[-0.09368545, -0.05541595, 0.042748727, -0.174...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>spam</td>\n",
              "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
              "      <td>chance win cash 100 20,000 pound txt &gt; send Co...</td>\n",
              "      <td>[six, chances, to, win, cash, from, to, pounds...</td>\n",
              "      <td>[six, chance, win, cash, 100, 20000, pound, tx...</td>\n",
              "      <td>[-0.08802351, -0.052317005, 0.040459823, -0.16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>spam</td>\n",
              "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
              "      <td>URGENT win 1 week free membership Prize Jackpo...</td>\n",
              "      <td>[urgent, you, have, won, week, free, membershi...</td>\n",
              "      <td>[urgent, 1, week, free, membership, 100000, pr...</td>\n",
              "      <td>[-0.090990104, -0.054207385, 0.041706238, -0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "      <td>search right word thank breather promise will ...</td>\n",
              "      <td>[ve, been, searching, for, the, right, words, ...</td>\n",
              "      <td>[ive, searching, right, word, thank, breather,...</td>\n",
              "      <td>[-0.10479991, -0.062377356, 0.04774809, -0.195...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>spam</td>\n",
              "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
              "      <td>use credit click WAP link txt message click &gt; &gt;</td>\n",
              "      <td>[to, use, your, credit, click, the, wap, link,...</td>\n",
              "      <td>[xxxmobilemovieclub, use, credit, click, wap, ...</td>\n",
              "      <td>[-0.106143996, -0.06288491, 0.048325885, -0.19...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12508af3-94d4-4b13-b932-94c109d17b7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12508af3-94d4-4b13-b932-94c109d17b7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12508af3-94d4-4b13-b932-94c109d17b7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Category                                               Text  \\\n",
              "0       ham  Go until jurong point, crazy.. Available only ...   \n",
              "1       ham                      Ok lar... Joking wif u oni...   \n",
              "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3       ham  U dun say so early hor... U c already then say...   \n",
              "4       ham  Nah I don't think he goes to usf, he lives aro...   \n",
              "5      spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
              "6       ham  Even my brother is not like to speak with me. ...   \n",
              "7       ham  As per your request 'Melle Melle (Oru Minnamin...   \n",
              "8      spam  WINNER!! As a valued network customer you have...   \n",
              "9      spam  Had your mobile 11 months or more? U R entitle...   \n",
              "10      ham  I'm gonna be home soon and i don't want to tal...   \n",
              "11     spam  SIX chances to win CASH! From 100 to 20,000 po...   \n",
              "12     spam  URGENT! You have won a 1 week FREE membership ...   \n",
              "13      ham  I've been searching for the right words to tha...   \n",
              "14     spam  XXXMobileMovieClub: To use your credit, click ...   \n",
              "\n",
              "                                            spacytext  \\\n",
              "0   point crazy available n great world la e buffe...   \n",
              "1                               ok lar joke wif u oni   \n",
              "2   free entry 2 comp win FA Cup final 21st 2005 t...   \n",
              "3                                 U dun early hor u c   \n",
              "4                                   nah think go live   \n",
              "5       hey darle 3 week word like fun Tb ok std send   \n",
              "6           brother like speak treat like aids patent   \n",
              "7   request Melle Melle Oru set Callers press 9 co...   \n",
              "8   WINNER value network customer select prize rew...   \n",
              "9   mobile 11 month u r entitle update late colour...   \n",
              "10  go to home soon want talk stuff anymore tonigh...   \n",
              "11  chance win cash 100 20,000 pound txt > send Co...   \n",
              "12  URGENT win 1 week free membership Prize Jackpo...   \n",
              "13  search right word thank breather promise will ...   \n",
              "14    use credit click WAP link txt message click > >   \n",
              "\n",
              "                                           simpletext  \\\n",
              "0   [go, until, jurong, point, crazy, available, o...   \n",
              "1                         [ok, lar, joking, wif, oni]   \n",
              "2   [free, entry, in, wkly, comp, to, win, fa, cup...   \n",
              "3      [dun, say, so, early, hor, already, then, say]   \n",
              "4   [nah, don, think, he, goes, to, usf, he, lives...   \n",
              "5   [freemsg, hey, there, darling, it, been, week,...   \n",
              "6   [even, my, brother, is, not, like, to, speak, ...   \n",
              "7   [as, per, your, request, melle, melle, oru, mi...   \n",
              "8   [winner, as, valued, network, customer, you, h...   \n",
              "9   [had, your, mobile, months, or, more, entitled...   \n",
              "10  [gonna, be, home, soon, and, don, want, to, ta...   \n",
              "11  [six, chances, to, win, cash, from, to, pounds...   \n",
              "12  [urgent, you, have, won, week, free, membershi...   \n",
              "13  [ve, been, searching, for, the, right, words, ...   \n",
              "14  [to, use, your, credit, click, the, wap, link,...   \n",
              "\n",
              "                                             nltktext  \\\n",
              "0   [go, jurong, point, crazy, available, bugis, n...   \n",
              "1                      [ok, lar, joking, wif, u, oni]   \n",
              "2   [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
              "3       [u, dun, say, early, hor, u, c, already, say]   \n",
              "4   [nah, dont, think, go, usf, life, around, though]   \n",
              "5   [freemsg, hey, darling, 3, week, word, back, i...   \n",
              "6   [even, brother, like, speak, treat, like, aid,...   \n",
              "7   [per, request, melle, melle, oru, minnaminungi...   \n",
              "8   [winner, valued, network, customer, selected, ...   \n",
              "9   [mobile, 11, month, u, r, entitled, update, la...   \n",
              "10  [im, gon, na, home, soon, dont, want, talk, st...   \n",
              "11  [six, chance, win, cash, 100, 20000, pound, tx...   \n",
              "12  [urgent, 1, week, free, membership, 100000, pr...   \n",
              "13  [ive, searching, right, word, thank, breather,...   \n",
              "14  [xxxmobilemovieclub, use, credit, click, wap, ...   \n",
              "\n",
              "                                         cbow_vectors  \n",
              "0   [-0.106335275, -0.06327503, 0.048476845, -0.19...  \n",
              "1   [-0.102702685, -0.061022747, 0.047203705, -0.1...  \n",
              "2   [-0.09802247, -0.05802328, 0.044908598, -0.182...  \n",
              "3   [-0.13842326, -0.08239722, 0.062801085, -0.258...  \n",
              "4   [-0.10480784, -0.062163178, 0.047725685, -0.19...  \n",
              "5   [-0.10340355, -0.06136291, 0.047242425, -0.192...  \n",
              "6   [-0.09139911, -0.053884435, 0.041671406, -0.17...  \n",
              "7   [-0.13480254, -0.0804047, 0.061284255, -0.2514...  \n",
              "8   [-0.11448016, -0.06814899, 0.052251305, -0.212...  \n",
              "9   [-0.08530863, -0.05060905, 0.03882869, -0.1585...  \n",
              "10  [-0.09368545, -0.05541595, 0.042748727, -0.174...  \n",
              "11  [-0.08802351, -0.052317005, 0.040459823, -0.16...  \n",
              "12  [-0.090990104, -0.054207385, 0.041706238, -0.1...  \n",
              "13  [-0.10479991, -0.062377356, 0.04774809, -0.195...  \n",
              "14  [-0.106143996, -0.06288491, 0.048325885, -0.19...  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna().reset_index(drop=True)\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G42BId9Rj647",
        "outputId": "f5895fde-bcec-4a58-8c60-2fea95c08493"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5518, 300)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create X from w2vec\n",
        "X_cbow = pd.DataFrame(df['cbow_vectors'].values.tolist())\n",
        "X_cbow.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mERq6YjTkeTT"
      },
      "outputs": [],
      "source": [
        "# label encode the 'label' \n",
        "le = LabelEncoder()\n",
        "# fit_transform() converts the text to numbers, for obtaining y\n",
        "y = le.fit_transform(df.Category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVwStBZmlWNT"
      },
      "outputs": [],
      "source": [
        "# split into train and test\n",
        "X_train_cb, X_test_cb, y_train_cb, y_test_cb = train_test_split(X_cbow, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f121AWukmH78",
        "outputId": "30937ea6-0c1c-4543-ea3f-59dd12ff93a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 85.59782608695652 %\n"
          ]
        }
      ],
      "source": [
        "# Build a text classification model\n",
        "# Initialize classifier\n",
        "model_1 = SVC()\n",
        "# Fit the model on the train dataset\n",
        "model_1 = model_1.fit(X_train_cb, y_train_cb)\n",
        "# Make predictions on the test dataset\n",
        "pred_1 = model_1.predict(X_test_cb)\n",
        "\n",
        "# check the accuracy of the model\n",
        "a1 = accuracy_score(y_test_cb, pred_1)\n",
        "print(\"Accuracy:\", a1*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAjib50VfX4v"
      },
      "source": [
        "## 2. Skipgram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D_csgDxfiyw"
      },
      "outputs": [],
      "source": [
        "# train a skipgram model from the given data set\n",
        "skgram_model = wtv(tokens, size=300, window=9, min_count=2, sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fO0xXJWfivr"
      },
      "outputs": [],
      "source": [
        "# extract vectors from all words in doc\n",
        "def get_embedding_sg(doc_tokens):\n",
        "    embeddings = []\n",
        "    model = skgram_model\n",
        "    # iterate over tokens to extract their vectors    \n",
        "    for tok in doc_tokens:\n",
        "        if tok in model.wv.vocab:\n",
        "            embeddings.append(model.wv.word_vec(tok))\n",
        "    # mean the vectors of individual words to get the vector of the statement\n",
        "    return np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4lRLe8DcLji"
      },
      "outputs": [],
      "source": [
        "df['sgram_vectors'] = df['Text'].apply(lambda x: get_embedding_sg(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYIwYtS5cLjl",
        "outputId": "9ff0bc1b-5877-4d03-82a9-8c0498fc08ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Category         0\n",
              "Text             0\n",
              "spacytext        0\n",
              "simpletext       0\n",
              "nltktext         0\n",
              "cbow_vectors     0\n",
              "sgram_vectors    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWFf7RoscaD7"
      },
      "source": [
        "Since all the problem rows have been already deleted so we have no issues here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0rtH2XBkor7",
        "outputId": "70a23b28-6000-4728-a134-7e06c6dfde31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5518, 300)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create X from w2vec\n",
        "X_skg = pd.DataFrame(df['sgram_vectors'].values.tolist())\n",
        "X_skg.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NuwZTvVlRji"
      },
      "outputs": [],
      "source": [
        "# label encode the 'label' \n",
        "le = LabelEncoder()\n",
        "# fit_transform() converts the text to numbers\n",
        "y = le.fit_transform(df.Category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt9gRYghmhJI"
      },
      "outputs": [],
      "source": [
        "# split into train and test\n",
        "X_train_sg, X_test_sg, y_train_sg, y_test_sg = train_test_split(X_skg, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2WMXNNNmhJK",
        "outputId": "02a8d13f-51d5-4d22-a4e8-6430d5c805c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 85.86956521739131 %\n"
          ]
        }
      ],
      "source": [
        "# Build a text classification model\n",
        "# Initialize classifier\n",
        "model_2 = SVC()\n",
        "# Fit the model on the train dataset\n",
        "model_2 = model_2.fit(X_train_sg, y_train_sg)\n",
        "# Make predictions on the test dataset\n",
        "pred_2 = model_2.predict(X_test_sg)\n",
        "\n",
        "# check the accuracy of the model\n",
        "a2 = accuracy_score(y_test_sg, pred_2)\n",
        "print(\"Accuracy:\", a2*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG14rneGffpU"
      },
      "source": [
        "## 3. Pretrained Google Word2Vec Model Based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3jjgdRdfzVs"
      },
      "outputs": [],
      "source": [
        "file_name = \"/content/drive/MyDrive/GoogleNews-vectors-negative300.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PmwemlxfzSk"
      },
      "outputs": [],
      "source": [
        "# load into gensim pretrained model\n",
        "google_w2vec = KeyedVectors.load_word2vec_format(file_name, binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J5r9pB4haup"
      },
      "outputs": [],
      "source": [
        "# extract vectors from all words in doc\n",
        "def get_embedding_ggl(doc_tokens):\n",
        "    embeddings = []\n",
        "    model = google_w2vec\n",
        "    # iterate over tokens to extract their vectors    \n",
        "    for tok in doc_tokens:\n",
        "        if tok in model.wv.vocab:\n",
        "            embeddings.append(model.wv.word_vec(tok))\n",
        "    # mean the vectors of individual words to get the vector of the statement\n",
        "    return np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np0jW55G-1n8",
        "outputId": "db666395-391e-4374-a099-dc6f9356b880"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "df['google_vectors'] = df['Text'].apply(lambda x: get_embedding_ggl(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNUVElZJhhAu",
        "outputId": "4ea6d757-347c-4760-af77-2882192f0f7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5518, 300)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create X from w2vec\n",
        "X_ggl = pd.DataFrame(df['google_vectors'].values.tolist())\n",
        "X_ggl.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnceEXCkk6cc"
      },
      "outputs": [],
      "source": [
        "# label encode the 'label' \n",
        "le = LabelEncoder()\n",
        "# fit_transform() converts the text to numbers\n",
        "y = le.fit_transform(df.Category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVEEG9cCmiwh"
      },
      "outputs": [],
      "source": [
        "# split into train and test\n",
        "X_train_gl, X_test_gl, y_train_gl, y_test_gl = train_test_split(X_ggl, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxSnUPAJmiwj",
        "outputId": "68473596-702d-4dc5-d134-e4c39789ff4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 97.01086956521739 %\n"
          ]
        }
      ],
      "source": [
        "# Build a text classification model\n",
        "# Initialize classifier\n",
        "model_3 = SVC()\n",
        "# Fit the model on the train dataset\n",
        "model_3 = model_3.fit(X_train_gl, y_train_gl)\n",
        "# Make predictions on the test dataset\n",
        "pred_3 = model_3.predict(X_test_gl)\n",
        "\n",
        "# check the accuracy of the model\n",
        "a3 = accuracy_score(y_test_gl, pred_3)\n",
        "print(\"Accuracy:\", a3*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PAZ-3XnA7Sl"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH39EcFcA-_3",
        "outputId": "cf52bd1c-98a9-4eac-fff1-832a0ca1f4f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\t\t\t Accuracy Of Email Classification Model \n",
            "CBOW Model\t\t\t\t:  0.8559782608695652 \n",
            "Skipgram Model \t\t\t\t:  0.8586956521739131 \n",
            "Pretrained Google Model \t\t:  0.970108695652174\n"
          ]
        }
      ],
      "source": [
        "print('\\n\\t\\t\\t Accuracy Of Email Classification Model',\n",
        "      '\\nCBOW Model\\t\\t\\t\\t: ',a1,\n",
        "      '\\nSkipgram Model \\t\\t\\t\\t: ',a2,\n",
        "      '\\nPretrained Google Model \\t\\t: ',a3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Aegcogu3FGVO",
        "Gk6V1GwdR2jL",
        "LleYP74F1N3O",
        "33pRq1qrbm2s",
        "Ot1023xrc_Et",
        "iAjib50VfX4v",
        "iG14rneGffpU",
        "9PAZ-3XnA7Sl"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
