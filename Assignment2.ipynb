{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7mGDvsyDKku"
      },
      "source": [
        "## Classification of News Articles\n",
        "\n",
        "News articles are one of the richest sources of data for many businesses. \n",
        "\n",
        "ABC company wants to build a website and recommend the contents to its users on their web application. \n",
        "\n",
        "So any new article or content that is coming, they wants to classify that into one of 5 categories: business, entertainment, politics, sport or tech. \n",
        "\n",
        "You are required to use a public dataset from the BBC each labelled under one of 5 categories: business, entertainment, politics, sport or tech.\n",
        "\n",
        "The goal will be to build a system that can accurately classify previously unseen news articles into the right category.\n",
        "\n",
        "\n",
        "The Evaluation metric you should use is the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYznKDVs6yld"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MBSG8F_90v1"
      },
      "outputs": [],
      "source": [
        "# Importing Count Vectorizer and TFIDF Vectorizer\n",
        "# We can carry out english stop words removal inside the CV or TFIDF\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
        "# Train Test Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Label Encoder \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Model Selection\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# Accuracy Score\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "6iAP6c109fqz",
        "outputId": "5fc9f944-4f7b-4a51-e4fd-f451c7f337f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2d1868af-9351-4673-8d25-3c6ddb82a23b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1833</td>\n",
              "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>154</td>\n",
              "      <td>german business confidence slides german busin...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1101</td>\n",
              "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1976</td>\n",
              "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>917</td>\n",
              "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d1868af-9351-4673-8d25-3c6ddb82a23b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d1868af-9351-4673-8d25-3c6ddb82a23b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d1868af-9351-4673-8d25-3c6ddb82a23b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   ArticleId                                               Text  Category\n",
              "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
              "1        154  german business confidence slides german busin...  business\n",
              "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
              "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
              "4        917  enron bosses in $168m payout eighteen former e...  business"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading dataset\n",
        "df = pd.read_csv('/content/BBC News.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIg5J95J9u0Y",
        "outputId": "116a5af7-5038-4a21-f2e0-07df32ae7d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1490 entries, 0 to 1489\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   ArticleId  1490 non-null   int64 \n",
            " 1   Text       1490 non-null   object\n",
            " 2   Category   1490 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 35.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MtkibXmSWB6",
        "outputId": "b9ec8ad3-54cb-4020-c6ac-5cedb595f09b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sport            346\n",
              "business         336\n",
              "politics         274\n",
              "entertainment    273\n",
              "tech             261\n",
              "Name: Category, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# different catogories\n",
        "df.Category.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "9qe9VjguSmXD",
        "outputId": "2e73fd14-d679-46ba-c940-2b775cd48b0d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers against a battery of fraud charges have called a company whistleblower as their first witness.  cynthia cooper  worldcom s ex-head of internal accounting  alerted directors to irregular accounting practices at the us telecoms giant in 2002. her warnings led to the collapse of the firm following the discovery of an $11bn (£5.7bn) accounting fraud. mr ebbers has pleaded not guilty to charges of fraud and conspiracy.  prosecution lawyers have argued that mr ebbers orchestrated a series of accounting tricks at worldcom  ordering employees to hide expenses and inflate revenues to meet wall street earnings estimates. but ms cooper  who now runs her own consulting business  told a jury in new york on wednesday that external auditors arthur andersen had approved worldcom s accounting in early 2001 and 2002. she said andersen had given a  green light  to the procedures and practices used by worldcom. mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.  ms cooper also said that during shareholder meetings mr ebbers often passed over technical questions to the company s finance chief  giving only  brief  answers himself. the prosecution s star witness  former worldcom financial chief scott sullivan  has said that mr ebbers ordered accounting adjustments at the firm  telling him to  hit our books . however  ms cooper said mr sullivan had not mentioned  anything uncomfortable  about worldcom s accounting during a 2001 audit committee meeting. mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing. worldcom emerged from bankruptcy protection in 2004  and is now known as mci. last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Text\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy-bXed698aG"
      },
      "source": [
        "## Preproccessing Using NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccL5EloNAUKi",
        "outputId": "23b0ad31-6ca6-454d-fa8c-299545706fe6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading NLTK module\n",
        "import nltk\n",
        "\n",
        "# downloading punkt\n",
        "nltk.download('punkt')\n",
        "\n",
        "# downloading stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDuhl1X1TWob"
      },
      "outputs": [],
      "source": [
        "# Importing Beautiful Soup for HTML parsing\n",
        "from bs4 import BeautifulSoup\n",
        "# Import RE\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VPHuRX-UlTq"
      },
      "outputs": [],
      "source": [
        "# Functions for various steps of Preprocessing\n",
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugy144-RUzkx"
      },
      "outputs": [],
      "source": [
        "# Apply function on Text column for noise removal\n",
        "df['ProText'] = df['Text'].apply(denoise_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgPNyo0nbLRP"
      },
      "outputs": [],
      "source": [
        "# Define function for removing special characters\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"I'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\^^\", \"\", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    return(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jXwihRkbUnI"
      },
      "outputs": [],
      "source": [
        "# Applying function on Text column for special characters removal\n",
        "df['ProText'] = df['Text'].apply(remove_special_characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTFKOaFWbumB"
      },
      "outputs": [],
      "source": [
        "#Stemming the text\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkQKN9Q-cHrR"
      },
      "outputs": [],
      "source": [
        "# Applying function on Text column for special characters removal\n",
        "df['ProText'] = df['Text'].apply(simple_stemmer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjxmS0v_ZOVs"
      },
      "outputs": [],
      "source": [
        "# Tokenize before stopword filtering\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "# Setting English stopwords\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5i1LgORcQX7"
      },
      "outputs": [],
      "source": [
        "# Instance creation for Tokenization of text\n",
        "tokenizer1=ToktokTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9UyXuSgc2TI"
      },
      "outputs": [],
      "source": [
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer1.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0J5yOnvdCD8"
      },
      "outputs": [],
      "source": [
        "# Applying function on Text column for stopword removal\n",
        "df['ProText'] = df['Text'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "JNTeVgCrdbdl",
        "outputId": "0233c9ba-5266-4688-e332-dfffe7405df3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers against a battery of fraud charges have called a company whistleblower as their first witness.  cynthia cooper  worldcom s ex-head of internal accounting  alerted directors to irregular accounting practices at the us telecoms giant in 2002. her warnings led to the collapse of the firm following the discovery of an $11bn (£5.7bn) accounting fraud. mr ebbers has pleaded not guilty to charges of fraud and conspiracy.  prosecution lawyers have argued that mr ebbers orchestrated a series of accounting tricks at worldcom  ordering employees to hide expenses and inflate revenues to meet wall street earnings estimates. but ms cooper  who now runs her own consulting business  told a jury in new york on wednesday that external auditors arthur andersen had approved worldcom s accounting in early 2001 and 2002. she said andersen had given a  green light  to the procedures and practices used by worldcom. mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.  ms cooper also said that during shareholder meetings mr ebbers often passed over technical questions to the company s finance chief  giving only  brief  answers himself. the prosecution s star witness  former worldcom financial chief scott sullivan  has said that mr ebbers ordered accounting adjustments at the firm  telling him to  hit our books . however  ms cooper said mr sullivan had not mentioned  anything uncomfortable  about worldcom s accounting during a 2001 audit committee meeting. mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing. worldcom emerged from bankruptcy protection in 2004  and is now known as mci. last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "i0zOFGDpd27o",
        "outputId": "ea7c6b3f-0e2a-4e26-e2cc-b35d93805188"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers battery fraud charges called company whistleblower first witness. cynthia cooper worldcom ex-head internal accounting alerted directors irregular accounting practices us telecoms giant 2002. warnings led collapse firm following discovery $ 11bn ( £ 5.7bn ) accounting fraud. mr ebbers pleaded guilty charges fraud conspiracy. prosecution lawyers argued mr ebbers orchestrated series accounting tricks worldcom ordering employees hide expenses inflate revenues meet wall street earnings estimates. ms cooper runs consulting business told jury new york wednesday external auditors arthur andersen approved worldcom accounting early 2001 2002. said andersen given green light procedures practices used worldcom. mr ebber lawyers said unaware fraud arguing auditors alert problems. ms cooper also said shareholder meetings mr ebbers often passed technical questions company finance chief giving brief answers himself. prosecution star witness former worldcom financial chief scott sullivan said mr ebbers ordered accounting adjustments firm telling hit books . however ms cooper said mr sullivan mentioned anything uncomfortable worldcom accounting 2001 audit committee meeting. mr ebbers could face jail sentence 85 years convicted charges facing. worldcom emerged bankruptcy protection 2004 known mci. last week mci agreed buyout verizon communications deal valued $ 6.75bn .'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.ProText[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEsLtBFGqWIa"
      },
      "source": [
        "## Preprocessing Using Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYsiixygYDXK"
      },
      "outputs": [],
      "source": [
        "# Import Spacy\n",
        "import spacy\n",
        "# Load English model for Tokenizer, Tagger, Parser and NER\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgrMoTTyqaSd"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    # remove stop words and lemmatize the text\n",
        "    doc = nlp(text)\n",
        "    filtered_tokens = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct or token.is_space:\n",
        "            continue\n",
        "        filtered_tokens.append(token.lemma_)\n",
        "    \n",
        "    return \" \".join(filtered_tokens) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab-MHWjqs5uO"
      },
      "outputs": [],
      "source": [
        "df['SpacyText'] = df['Text'].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "fyi9X36GtS-l",
        "outputId": "3ee0ed2b-6f8c-4b02-fd91-47b86dab1d17"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers against a battery of fraud charges have called a company whistleblower as their first witness.  cynthia cooper  worldcom s ex-head of internal accounting  alerted directors to irregular accounting practices at the us telecoms giant in 2002. her warnings led to the collapse of the firm following the discovery of an $11bn (£5.7bn) accounting fraud. mr ebbers has pleaded not guilty to charges of fraud and conspiracy.  prosecution lawyers have argued that mr ebbers orchestrated a series of accounting tricks at worldcom  ordering employees to hide expenses and inflate revenues to meet wall street earnings estimates. but ms cooper  who now runs her own consulting business  told a jury in new york on wednesday that external auditors arthur andersen had approved worldcom s accounting in early 2001 and 2002. she said andersen had given a  green light  to the procedures and practices used by worldcom. mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.  ms cooper also said that during shareholder meetings mr ebbers often passed over technical questions to the company s finance chief  giving only  brief  answers himself. the prosecution s star witness  former worldcom financial chief scott sullivan  has said that mr ebbers ordered accounting adjustments at the firm  telling him to  hit our books . however  ms cooper said mr sullivan had not mentioned  anything uncomfortable  about worldcom s accounting during a 2001 audit committee meeting. mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing. worldcom emerged from bankruptcy protection in 2004  and is now known as mci. last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "vFwbDSestStO",
        "outputId": "a88b2519-e576-44b3-fde8-e7da3ef41ab4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'worldcom ex boss launch defence lawyer defend worldcom chief bernie ebber battery fraud charge call company whistleblow witness cynthia cooper worldcom s ex head internal accounting alert director irregular accounting practice telecoms giant 2002 warning lead collapse firm follow discovery $ 11bn £ 5.7bn accounting fraud mr ebber plead guilty charge fraud conspiracy prosecution lawyer argue mr ebber orchestrate series accounting trick worldcom order employee hide expense inflate revenue meet wall street earning estimate ms cooper run consulting business tell jury new york wednesday external auditor arthur andersen approve worldcom s accounting early 2001 2002 say andersen give green light procedure practice worldcom mr ebber s lawyer say unaware fraud argue auditor alert problem ms cooper say shareholder meeting mr ebber pass technical question company s finance chief give brief answer prosecution s star witness worldcom financial chief scott sullivan say mr ebber order accounting adjustment firm tell hit book ms cooper say mr sullivan mention uncomfortable worldcom s accounting 2001 audit committee meeting mr ebber face jail sentence 85 year convict charge face worldcom emerge bankruptcy protection 2004 know mci week mci agree buyout verizon communication deal value $ 6.75bn'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.SpacyText[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVC3kogRoH0k"
      },
      "source": [
        "## Count Vectorizer with ProText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAk8Wp6VeSuk"
      },
      "outputs": [],
      "source": [
        "# Create the COUNT VECTORIZER instance\n",
        "# Model defined also\n",
        "vect = CountVectorizer(ngram_range=(1,2), max_features=800).fit(df['ProText'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f8i5SkhfzQR"
      },
      "outputs": [],
      "source": [
        "# Fit and transform Model\n",
        "X = vect.transform(df.ProText)\n",
        "# Convert to a dataframe \n",
        "X = pd.DataFrame(X.toarray(), columns=vect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S43L8OU9haMH"
      },
      "outputs": [],
      "source": [
        "# Applying Label encoder for the Category?output column\n",
        "le = LabelEncoder()\n",
        "fit = le.fit(df['Category'])\n",
        "y = fit.transform(df['Category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gey7X0r8ikqq"
      },
      "outputs": [],
      "source": [
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kACoatyVkhYI",
        "outputId": "1056e0df-5485-438e-db60-d9705e64aec2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1192, 800), (1192,))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrknKEvkksUc",
        "outputId": "862c15e1-1965-4c78-acf8-1d72fcff002b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score for model with Count Vectorizer:  0.9731543624161074\n"
          ]
        }
      ],
      "source": [
        "# Creating instance for Multinomial Naive Bayes\n",
        "lr = MultinomialNB()\n",
        "# Training the model\n",
        "lr.fit(X_train, y_train)\n",
        "# Predicting the output\n",
        "y_pred = lr.predict(X_test)\n",
        "# Accuracy Score\n",
        "a1 = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy Score for model with Count Vectorizer: ',a1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRCma7VQqq6h"
      },
      "source": [
        "## Count Vectorizer with SpacyText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOa0Qqlwq7rE"
      },
      "outputs": [],
      "source": [
        "# Create the COUNT VECTORIZER instance\n",
        "# Model defined also\n",
        "vect1 = CountVectorizer(ngram_range=(1,2), max_features=800).fit(df['SpacyText'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6CWBqPpq7rG"
      },
      "outputs": [],
      "source": [
        "# Fit and transform Model\n",
        "X1 = vect1.transform(df.SpacyText)\n",
        "# Convert to a dataframe \n",
        "X1 = pd.DataFrame(X1.toarray(), columns=vect1.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBfhAXC6q7rH"
      },
      "outputs": [],
      "source": [
        "# Applying Label encoder for the Category?output column\n",
        "le = LabelEncoder()\n",
        "fit = le.fit(df['Category'])\n",
        "y = fit.transform(df['Category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgOrbhmVq7rI"
      },
      "outputs": [],
      "source": [
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBqV2m-Oq7rJ",
        "outputId": "1f047600-d2e7-4baf-dda0-8d89ff4d089c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1192, 800), (1192,))"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wF9vYSPq7rK",
        "outputId": "ccd38a5f-b0c2-4242-8680-e882548e3c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score for model(Spacy) with Count Vectorizer:  0.9664429530201343\n"
          ]
        }
      ],
      "source": [
        "# Creating instance for Multinomial Naive Bayes\n",
        "lr1 = MultinomialNB()\n",
        "# Training the model\n",
        "lr1.fit(X_train, y_train)\n",
        "# Predicting the output\n",
        "y_pred = lr1.predict(X_test)\n",
        "# Accuracy Score\n",
        "a2 = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy Score for model(Spacy) with Count Vectorizer: ',accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYRKsKbNyQok"
      },
      "source": [
        "## TFIDF Vectorizer with ProText\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tmv2Yv7wxGLb"
      },
      "outputs": [],
      "source": [
        "# Create the TFIDF Vectorizer instance\n",
        "# Model defined also\n",
        "vect2 = TfidfVectorizer(ngram_range=(1,2), max_features=800).fit(df['ProText'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JEWFwgtxKgo"
      },
      "outputs": [],
      "source": [
        "# Fit and transform Model\n",
        "X2 = vect2.transform(df.ProText)\n",
        "# Convert to a dataframe \n",
        "X2 = pd.DataFrame(X2.toarray(), columns=vect2.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEzvsPyM0heu"
      },
      "outputs": [],
      "source": [
        "# Applying Label encoder for the Category?output column\n",
        "le = LabelEncoder()\n",
        "fit = le.fit(df['Category'])\n",
        "y = fit.transform(df['Category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIGhvP5U0hew"
      },
      "outputs": [],
      "source": [
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjVTcgib0hex",
        "outputId": "4df3a9f8-a8c3-463a-baa3-f84c499ce3c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1192, 800), (1192,))"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BmX8gUk0hez",
        "outputId": "adfb1c9f-63c9-489c-f39a-1640ff20d25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score for model with TFIDF Vectorizer:  0.9630872483221476\n"
          ]
        }
      ],
      "source": [
        "# Creating instance for Multinomial Naive Bayes\n",
        "lr = MultinomialNB()\n",
        "# Training the model\n",
        "lr.fit(X_train, y_train)\n",
        "# Predicting the output\n",
        "y_pred = lr.predict(X_test)\n",
        "# Accuracy Score\n",
        "a3 = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy Score for model with TFIDF Vectorizer: ',accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnPHSZccydmt"
      },
      "source": [
        "## TFIDF Vectorizer with SpacyText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-QZ9YpZ1PnL"
      },
      "outputs": [],
      "source": [
        "# Create the TFIDF Vectorizer instance\n",
        "# Model defined also\n",
        "vect3 = TfidfVectorizer(ngram_range=(1,2), max_features=1000).fit(df['SpacyText'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2BC1ghq1PnO"
      },
      "outputs": [],
      "source": [
        "# Fit and transform Model\n",
        "X3 = vect3.transform(df.SpacyText)\n",
        "# Convert to a dataframe \n",
        "X3 = pd.DataFrame(X3.toarray(), columns=vect3.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5M0ydU1n1PnP"
      },
      "outputs": [],
      "source": [
        "# Applying Label encoder for the Category?output column\n",
        "le = LabelEncoder()\n",
        "fit = le.fit(df['Category'])\n",
        "y = fit.transform(df['Category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYJ6oRa91PnQ"
      },
      "outputs": [],
      "source": [
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X3, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o98wwNbb1PnR",
        "outputId": "1e76da9c-f209-4f59-cb58-f99b2d091d92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1192, 1000), (1192,))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPM42uxr1PnS",
        "outputId": "7ab696fc-d4de-4720-f594-eb0da6089757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score for model with TFIDF Vectorizer:  0.959731543624161\n"
          ]
        }
      ],
      "source": [
        "# Creating instance for Multinomial Naive Bayes \n",
        "lr = MultinomialNB()\n",
        "# Training the model\n",
        "lr.fit(X_train, y_train)\n",
        "# Predicting the output\n",
        "y_pred = lr.predict(X_test)\n",
        "# Accuracy Score\n",
        "a4 = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy Score for model with TFIDF Vectorizer: ',accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53ouuw4N7jgv"
      },
      "source": [
        "## Result Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzWGxR_b7htL",
        "outputId": "e654813d-36a9-481b-f2e5-e3f9a34fe226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Results\n",
            " Models\t\t\t\t\t\t Accuracy Score \n",
            "Count Vectorizer with NLTK Preprocessing \t: 0.9731543624161074 \n",
            "Count Vectorizer with Spacy Preprocessing \t: 0.9664429530201343 \n",
            "TFIDF Vectorizer with NLTK Preprocessing \t: 0.9630872483221476 \n",
            "TFIDF Vectorizer with Spacy Preprocessing \t: 0.959731543624161\n"
          ]
        }
      ],
      "source": [
        "print('\\nFinal Results\\n', \n",
        "      'Models\\t\\t\\t\\t\\t\\t Accuracy Score',\n",
        "      '\\nCount Vectorizer with NLTK Preprocessing \\t:', a1,\n",
        "      '\\nCount Vectorizer with Spacy Preprocessing \\t:', a2,\n",
        "      '\\nTFIDF Vectorizer with NLTK Preprocessing \\t:', a3,\n",
        "      '\\nTFIDF Vectorizer with Spacy Preprocessing \\t:', a4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjokcrF3_nk9"
      },
      "source": [
        "We can come to the following conclusions:\n",
        "\n",
        "1.   The Count Vectorizer seems to yield a marginally better result than TFIDF Vectorizer for both preprocessing instances\n",
        "2.   The NLTK preprocessing model seems to yield better results than the Spacy model\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_7mGDvsyDKku",
        "Jy-bXed698aG",
        "pEsLtBFGqWIa",
        "qVC3kogRoH0k",
        "VRCma7VQqq6h",
        "fYRKsKbNyQok",
        "LnPHSZccydmt",
        "53ouuw4N7jgv"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
